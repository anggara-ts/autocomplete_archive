
@misc{_visual_????,
	title = {Visual {Business} {Intelligence} – {The} {Slow} {Data} {Movement}: {My} {Hope} for 2013},
	url = {http://www.perceptualedge.com/blog/?p=1460},
	urldate = {2015-03-07},
	file = {Visual Business Intelligence – The Slow Data Movement\: My Hope for 2013:/Users/gabrielgianordoli/Library/Application Support/Zotero/Profiles/74teao9p.default/zotero/storage/CUBBPJS7/blog.html:text/html}
}

@misc{_big_????,
	title = {Big data {\textbar} {Pierre} {Levy}'s {Blog}},
	url = {http://pierrelevyblog.com/tag/big-data/},
	urldate = {2015-03-08},
	file = {Big data | Pierre Levy's Blog:/Users/gabrielgianordoli/Library/Application Support/Zotero/Profiles/74teao9p.default/zotero/storage/8WWD8BQV/big-data.html:text/html}
}

@book{fry_visualizing_2008,
	address = {Sebastopol, CA},
	edition = {1 edition},
	title = {Visualizing {Data}: {Exploring} and {Explaining} {Data} with the {Processing} {Environment}},
	isbn = {9780596514556},
	shorttitle = {Visualizing {Data}},
	abstract = {Enormous quantities of data go unused or underused today, simply because people can't visualize the quantities and relationships in it. Using a downloadable programming environment developed by the author, Visualizing Data demonstrates methods for representing data accurately on the Web and elsewhere, complete with user interaction, animation, and more.How do the 3.1 billion A, C, G and T letters of the human genome compare to those of a chimp or a mouse? What do the paths that millions of visitors take through a web site look like? With Visualizing Data, you learn how to answer complex questions like these with thoroughly interactive displays. We're not talking about cookie-cutter charts and graphs. This book teaches you how to design entire interfaces around large, complex data sets with the help of a powerful new design and prototyping tool called "Processing".Used by many researchers and companies to convey specific data in a clear and understandable manner, the Processing beta is available free. With this tool and Visualizing Data as a guide, you'll learn basic visualization principles, how to choose the right kind of display for your purposes, and how to provide interactive features that will bring users to your site over and over. This book teaches you:The seven stages of visualizing data -- acquire, parse, filter, mine, represent, refine, and interactHow all data problems begin with a question and end with a narrative construct that provides a clear answer without extraneous detailsSeveral example projects with the code to make them workPositive and negative points of each representation discussed. The focus is on customization so that each one best suits what you want to convey about your data setThe book does not provide ready-made "visualizations" that can be plugged into any data set. Instead, with chapters divided by types of data rather than types of display, you'll learn how each visualization conveys the unique properties of the data it represents -- why the data was collected, what's interesting about it, and what stories it can tell. Visualizing Data teaches you how to answer questions, not simply display information.},
	language = {English},
	publisher = {O'Reilly Media},
	author = {Fry, Ben},
	month = jan,
	year = {2008}
}

@misc{_ng_????,
	title = {{NG} {Live}!: {Jer} {Thorp}: {Numbers} {That} {Paint} the {Picture}},
	shorttitle = {{NG} {Live}!},
	url = {http://video.nationalgeographic.com/video/ng-live/thorp-data-lecture-nglive},
	abstract = {National Geographic Emerging Explorer and data artist\&nbsp;Jer\&nbsp;Thorp\&nbsp;translates unimaginable blurs of information into something we can see, understand, and feel—data made human through visualizations that blend research, art, software, science, and design.The National Geographic Live! series brings thought-provoking presentations\&nbsp;by today’s leading explorers, scientists, photographers, and performing artists right to your YouTube feed. Each presentation is filmed in front of a live audience at National Geographic headquarters in Washington, D.C. New clips air every Monday.},
	urldate = {2015-03-08},
	file = {Snapshot:/Users/gabrielgianordoli/Library/Application Support/Zotero/Profiles/74teao9p.default/zotero/storage/A65W9EWU/thorp-data-lecture-nglive.html:text/html}
}

@article{paul_encyclopedia_????,
	title = {Encyclopedia of {Library} and {Information} {Sciences}},
	url = {http://www.tandfonline.com/doi/abs/10.1081/E-ELIS3-120043697},
	urldate = {2015-03-08},
	author = {Paul, Christiane and Toolin, Jack},
	file = {ELIS_text_update 2014_CP.pdf:/Users/gabrielgianordoli/Library/Application Support/Zotero/Profiles/74teao9p.default/zotero/storage/39M9DWR7/ELIS_text_update 2014_CP.pdf:application/pdf}
}

@book{paul_database_2007,
	title = {The database as system and cultural form: {Anatomies} of cultural narratives},
	shorttitle = {The database as system and cultural form},
	url = {http://visualizinginfo.pbworks.com/f/db-system-culturalform.pdf},
	urldate = {2015-03-08},
	publisher = {na},
	author = {Paul, Christiane},
	year = {2007},
	file = {Paul_DatabaseAsSystemAndCulturalForm.pdf:/Users/gabrielgianordoli/Library/Application Support/Zotero/Profiles/74teao9p.default/zotero/storage/S7BFWQ44/Paul_DatabaseAsSystemAndCulturalForm.pdf:application/pdf}
}

@article{manovich_cultural_2009,
	title = {Cultural {Analytics}: {Visualising} {Cultural} {Patterns} in the {Era} of “{More} {Media}”},
	shorttitle = {Cultural {Analytics}},
	url = {http://manovich.net/content/04-projects/061-cultural-analytics-visualizing-cultural-patterns/60_article_2009.pdf},
	urldate = {2015-03-08},
	journal = {Domus,(Milan), March},
	author = {Manovich, Lev},
	year = {2009},
	file = {manovich_cultural_analytics.pdf:/Users/gabrielgianordoli/Library/Application Support/Zotero/Profiles/74teao9p.default/zotero/storage/4D39PXKS/manovich_cultural_analytics.pdf:application/pdf}
}

@article{laney_3-d_2001,
	title = {3-{D} {Data} {Management}: {Controlling} {Data} {Volume}, {Velocity} and {Variety}},
	volume = {949},
	url = {http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf},
	journal = {Application Delivery Strategies by META Group Inc.},
	author = {Laney, Doug},
	month = feb,
	year = {2001}
}

@misc{_big_2015,
	title = {Big data},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Big_data&oldid=650299928},
	abstract = {Big data is a broad term for data sets so large or complex that traditional data processing applications are inadequate. Challenges include analysis, capture, curation, search, sharing, storage, transfer, visualization, and information privacy. The term often refers simply to the use of predictive analytics or other certain advanced methods to extract value from data, and seldom to a particular size of data set.
Analysis of data sets can find new correlations, to "spot business trends, prevent diseases, combat crime and so on." Scientists, practitioners of media and advertising and governments alike regularly meet difficulties with large data sets in areas including Internet search, finance and business informatics. Scientists encounter limitations in e-Science work, including meteorology, genomics, connectomics, complex physics simulations, and biological and environmental research.
Data sets grow in size in part because they are increasingly being gathered by cheap and numerous information-sensing mobile devices, aerial (remote sensing), software logs, cameras, microphones, radio-frequency identification (RFID) readers, and wireless sensor networks. The world's technological per-capita capacity to store information has roughly doubled every 40 months since the 1980s; as of 2012, every day 2.5 exabytes (2.5×1018) of data were created; The challenge for large enterprises is determining who should own big data initiatives that straddle the entire organization.
Relational database management systems and desktop statistics and visualization packages often have difficulty handling big data. The work instead requires "massively parallel software running on tens, hundreds, or even thousands of servers". What is considered "big data" varies depending on the capabilities of the users and their tools, and expanding capabilities make Big Data a moving target. Thus, what is considered to be "Big" in one year will become ordinary in later years. "For some organizations, facing hundreds of gigabytes of data for the first time may trigger a need to reconsider data management options. For others, it may take tens or hundreds of terabytes before data size becomes a significant consideration."},
	language = {en},
	urldate = {2015-03-09},
	journal = {Wikipedia, the free encyclopedia},
	month = mar,
	year = {2015},
	note = {Page Version ID: 650299928},
	file = {Snapshot:/Users/gabrielgianordoli/Library/Application Support/Zotero/Profiles/74teao9p.default/zotero/storage/EAAQ4JW3/index.html:text/html}
}